{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Embeddings"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import itertools\n",
    "import sqlite3\n",
    "from typing import List\n",
    "import itertools\n",
    "import pandas as pd\n",
    "from typing import *"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create your connection.\n",
    "db = sqlite3.connect('../stackoverflow.db')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tag_df = pd.read_sql_query(\"SELECT * FROM Tag\", db)\n",
    "tag_df.set_index('TagId', inplace=True)\n",
    "tag_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "POST_LIMIT = 500000\n",
    "post_df = pd.read_sql_query(f\"SELECT * FROM Post LIMIT {POST_LIMIT}\", db)\n",
    "post_df.set_index('PostId', inplace=True)\n",
    "post_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "BADGE_LIMIT = 500000\n",
    "badge_df = pd.read_sql_query(f\"SELECT * FROM badge LIMIT {BADGE_LIMIT}\", db)\n",
    "badge_df.set_index('BadgeId', inplace=True)\n",
    "badge_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "user_LIMIT = 500000\n",
    "user_df = pd.read_sql_query(f\"SELECT * FROM user LIMIT {user_LIMIT}\", db)\n",
    "user_df.set_index('UserId', inplace=True)\n",
    "user_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "comment_LIMIT = 500000\n",
    "comment_df = pd.read_sql_query(f\"SELECT * FROM comment LIMIT {comment_LIMIT}\", db)\n",
    "comment_df.set_index('CommentId', inplace=True)\n",
    "comment_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "vote_LIMIT = 500000\n",
    "vote_df = pd.read_sql_query(f\"SELECT * FROM vote LIMIT {vote_LIMIT}\", db)\n",
    "vote_df.set_index('VoteId', inplace=True)\n",
    "vote_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "So, we want to build an embedding for the body of posts.\n",
    "The body of posts are stored as HTML, we need to split up the text and the code snippets so we can process them separately."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sample_post = post_df.head(1)\n",
    "sample_post"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's process the Body first"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import spacy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchtext.vocab import GloVe\n",
    "\n",
    "en = spacy.load('en_core_web_sm')\n",
    "stopwords = en.Defaults.stop_words"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class PostEmbedding(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self._global_vectors = GloVe(name='840B', dim=300)\n",
    "\n",
    "    def forward(self, html: str, title: str, flatten=True) -> torch.tensor:\n",
    "        soup = BeautifulSoup(html)\n",
    "        ps = self.get_paragraphs(soup, title)\n",
    "        if flatten:\n",
    "            # Treat all paragraphs the same\n",
    "            ps = [token for para in ps for token in para]\n",
    "\n",
    "        para_emb = self.to_paragraph_embedding(ps)\n",
    "\n",
    "        code = self.get_code(soup)\n",
    "        return para_emb\n",
    "\n",
    "    def preprocess(self, text: str) -> List[str]:\n",
    "        doc = en(text.lower())\n",
    "        tokens = [word.text for word in doc if not (word.is_stop or word.is_punct or word.like_num)]\n",
    "        return tokens\n",
    "\n",
    "    def get_paragraphs(self, soup: BeautifulSoup, title: str=None) -> List[List[str]]:\n",
    "        paras = [self.preprocess(x.get_text()) for x in soup.find_all('p')]\n",
    "        # If title is available add it to the paragraphs\n",
    "        if title is not None:\n",
    "            paras += self.preprocess(title)\n",
    "        return paras\n",
    "\n",
    "    def to_paragraph_embedding(self, tokens: List[str]):\n",
    "        word_embeddings = self._global_vectors.get_vecs_by_tokens(tokens)\n",
    "        return torch.sum(word_embeddings, dim=0) / len(tokens)\n",
    "\n",
    "\n",
    "    def get_code(self, soup: BeautifulSoup) -> str:\n",
    "        return \"\\n\".join([x.get_text() for x in soup.find_all('code')])\n",
    "\n",
    "\n",
    "html = sample_post['Body'].item()\n",
    "\n",
    "embedding = PostEmbedding()\n",
    "embedding(html, sample_post['Title'].item())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pe = PostEmbedding()\n",
    "post_df['code_snippets'] = post_df['Body'].apply(lambda html: pe.get_code(BeautifulSoup(html)))\n",
    "post_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "python_class_name_pattern = r\"class ([a-zA-Z_$][a-zA-Z_$0-9]*)[:(]\"\n",
    "py_func_name_pattern = r\"def ([a-zA-Z_$][a-zA-Z_$0-9]*)\\(\"\n",
    "py_import_pattern = r\"(?m)^(?:from[ ]+(\\S+)[ ]+)?import[ ]+(\\S+)(?:[ ]+as[ ]+\\S+)?[ ]*$\"\n",
    "py_variable_names = r\"([a-zA-Z_$0-9]+)[ ]=\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def find_code_features(code_snippet: str):\n",
    "    class_names = re.findall(python_class_name_pattern, code_snippet)\n",
    "    func_names = re.findall(py_func_name_pattern, code_snippet)\n",
    "    import_names = list(sum(re.findall(py_import_pattern, code_snippet), ()))\n",
    "    var_names = re.findall(py_variable_names, code_snippet)\n",
    "    # return {\n",
    "    #     'class_names' : class_names,\n",
    "    #     'func_names' : func_names,\n",
    "    #     'import_names' : import_names,\n",
    "    #     'var_names' : var_names\n",
    "    # }\n",
    "    return import_names\n",
    "\n",
    "post_df['import_names'] = post_df['code_snippets'].apply(find_code_features)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "post_df[['code_snippets', 'import_names']]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "a = post_df[['code_snippets', 'import_names']]\n",
    "a.dtypes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Building the graph\n",
    "We want to build a user-expertise graph"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "USER_ID = 653\n",
    "user_df.loc[USER_ID]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "questions_by_user = pd.read_sql_query(f\"SELECT * FROM Post WHERE OwnerUserId={USER_ID} AND PostTypeId=1\", db)\n",
    "questions_by_user.set_index('PostId', inplace=True)\n",
    "questions_by_user"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "answers_by_user = pd.read_sql_query(f\"SELECT * FROM Post WHERE OwnerUserId={USER_ID} AND PostTypeId=2\", db)\n",
    "answers_by_user.set_index('PostId', inplace=True)\n",
    "answers_by_user"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "comments_by_user = pd.read_sql_query(f\"SELECT * FROM Comment WHERE UserId={USER_ID}\", db)\n",
    "comments_by_user.set_index('CommentId', inplace=True)\n",
    "comments_by_user"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def parse_tag_list(tag_list: str) -> List[str]:\n",
    "    return tag_list[1:-1].split(\"><\")\n",
    "\n",
    "def get_parent_tags(post_id: int) -> str:\n",
    "    tags = pd.read_sql_query(f\"SELECT Tags FROM Post WHERE PostId={post_id}\", db)\n",
    "    return tags['Tags'].item()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tag_frequency = {}\n",
    "\n",
    "for i, row in questions_by_user.iterrows():\n",
    "    tags = parse_tag_list(row.Tags)\n",
    "    for t in tags:\n",
    "        if t in tag_frequency:\n",
    "            tag_frequency[t] += 1\n",
    "        else:\n",
    "            tag_frequency[t] = 1\n",
    "\n",
    "for i, row in answers_by_user.iterrows():\n",
    "    tag_list = get_parent_tags(row.ParentId)\n",
    "    if tag_list is None:\n",
    "        continue\n",
    "    for t in parse_tag_list(tag_list):\n",
    "        if t in tag_frequency:\n",
    "            tag_frequency[t] += 1\n",
    "        else:\n",
    "            tag_frequency[t] = 1\n",
    "\n",
    "{k: v for k, v in sorted(tag_frequency.items(), key=lambda item: item[1], reverse=True)}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "So we can see there are many categories and for a single user; but there is a lot of variance.\n",
    "Can we create an embedding for tags which reflect similar categories?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Step 1. Build list of Tag vocabulary"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tag_df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tag_df[\"TagName\"].to_csv(\"tag_vocab.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tag_vocab = list(set(tag_df[\"TagName\"]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "post_tags = pd.read_sql_query(f\"SELECT Tags FROM Post WHERE PostTypeId=1\", db)\n",
    "post_tags.to_csv(\"all_tags.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "post_tags = pd.read_csv(\"all_tags.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tag_list_df = post_tags['Tags'].apply(lambda row: parse_tag_list(row))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "combinations = tag_list_df.apply(lambda row: list(itertools.combinations(row, 2)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "combinations = combinations[combinations.astype(str) != '[]']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tag_pairs = []\n",
    "for i in combinations:\n",
    "    tag_pairs += i"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "TRAIN_SIZE = 10000\n",
    "tag_pairs = random.sample(tag_pairs, TRAIN_SIZE)\n",
    "tag_pairs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(tag_pairs), len(tag_vocab)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tag_to_ix = {tag: i for i, tag in enumerate(tag_vocab)}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class TagEmbedding(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embedding_dim):\n",
    "        super(TagEmbedding, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.linear1 = nn.Linear(embedding_dim, 128)\n",
    "        self.linear2 = nn.Linear(128, vocab_size)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        embeds = self.embedding(inputs).view((1, -1))\n",
    "        out = F.relu(self.linear1(embeds))\n",
    "        out = self.linear2(out)\n",
    "        log_probs = F.log_softmax(out, dim=1)\n",
    "        return log_probs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "losses = []\n",
    "loss_function = nn.NLLLoss()\n",
    "model = TagEmbedding(vocab_size=len(tag_vocab), embedding_dim=20).to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for epoch in range(1):\n",
    "    total_loss = 0\n",
    "    for tag_a, tag_b in tqdm(tag_pairs):\n",
    "        tag_a_id = torch.tensor(tag_to_ix[tag_a], dtype=torch.long).to(device)\n",
    "        model.zero_grad()\n",
    "        log_probs = model(tag_a_id)\n",
    "        loss = loss_function(log_probs.flatten(), torch.tensor(tag_to_ix[tag_b], dtype=torch.long).to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    losses.append(total_loss)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "embd_a = model.embedding.weight[tag_to_ix[\"python\"]]\n",
    "embd_b = model.embedding.weight[tag_to_ix[\"java\"]]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sim = torch.nn.CosineSimilarity(dim=0)\n",
    "sim(embd_a, embd_b)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter('runs/visualisation2')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tag_vocab"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "loaded_model = torch.load(\"10mil.pt\", map_location=torch.device('cpu'))\n",
    "writer.add_embedding(loaded_model.embedding.weight,\n",
    "                         metadata  = tag_vocab,\n",
    "                        tag = f'Tag embedding')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "writer.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
